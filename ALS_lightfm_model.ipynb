{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import implicit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.sparse as sp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains two models for the recommendation system.  The Implicit and lightfm libraries will be used for the models.  The Implicit model was chosen because the type of data we have for the reccomender is implicit meaning, only interactions are stored and not user supplied ratings as in explicit data.  Implicit data, while more difficult to interpret, is generated in much larger amounts than explicit.  While implicit data is more vague, the volume of data should help the model perform better.  The lightfm library was chosen for its capability of constructing hybrid models where user and item features can be supplied.  Including user and content features helps to mitigate the cold start problem where the user/item matrix has difficulty making adequate recommendation due to its sparsity.  Constructing a hybrid model is beyond the scope of this project.  However, lightfm was chosen in the event the project is further developed into a hybrid model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating user/item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "le = pd.read_csv('nprs_final.csv',usecols=['user_id','track_id','created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>2014-01-01 05:54:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>2014-02-19 11:21:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>2014-03-02 15:28:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>2014-03-04 01:32:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>2014-04-07 20:20:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                          track_id           created_at\n",
       "0  81496937  cd52b3e5b51da29e5893dba82a418a4b  2014-01-01 05:54:21\n",
       "1  81496937  cd52b3e5b51da29e5893dba82a418a4b  2014-02-19 11:21:51\n",
       "2  81496937  cd52b3e5b51da29e5893dba82a418a4b  2014-03-02 15:28:20\n",
       "3  81496937  cd52b3e5b51da29e5893dba82a418a4b  2014-03-04 01:32:31\n",
       "4  81496937  cd52b3e5b51da29e5893dba82a418a4b  2014-04-07 20:20:46"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "les = le.sort_values(by='created_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>2014-01-01 05:54:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>2205686924</td>\n",
       "      <td>da3110a77b724072b08f231c9d6f7534</td>\n",
       "      <td>2014-01-01 05:54:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631443</th>\n",
       "      <td>97675221</td>\n",
       "      <td>33f95122281f76e7134f9cbea3be980f</td>\n",
       "      <td>2014-01-01 05:54:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753822</th>\n",
       "      <td>452285741</td>\n",
       "      <td>8bd5206b84c968eda0af8bc86d6ab1d1</td>\n",
       "      <td>2014-01-01 05:54:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836237</th>\n",
       "      <td>65086276</td>\n",
       "      <td>23ced06ca57d37fa749b1595bc7ed1a4</td>\n",
       "      <td>2014-01-01 05:54:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                          track_id           created_at\n",
       "0         81496937  cd52b3e5b51da29e5893dba82a418a4b  2014-01-01 05:54:21\n",
       "20036   2205686924  da3110a77b724072b08f231c9d6f7534  2014-01-01 05:54:22\n",
       "631443    97675221  33f95122281f76e7134f9cbea3be980f  2014-01-01 05:54:24\n",
       "753822   452285741  8bd5206b84c968eda0af8bc86d6ab1d1  2014-01-01 05:54:25\n",
       "836237    65086276  23ced06ca57d37fa749b1595bc7ed1a4  2014-01-01 05:54:28"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "les.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign each event a count of 1\n",
    "les['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by user/item id and sum counts\n",
    "rating = les.groupby(['user_id','track_id'],as_index=False)['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10221</td>\n",
       "      <td>03b403c0ecede5105ac9f3880a7a480a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10221</td>\n",
       "      <td>09553c80ea087b5885436c627f00f482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10221</td>\n",
       "      <td>1c23db8ed72b8a1e44f4b5af9d7739bf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10221</td>\n",
       "      <td>299c9ab0f09d8dc281deaaad3260853e</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10221</td>\n",
       "      <td>34619be190aa19b20492e13da0cc1e45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                          track_id  count\n",
       "0    10221  03b403c0ecede5105ac9f3880a7a480a      3\n",
       "1    10221  09553c80ea087b5885436c627f00f482      1\n",
       "2    10221  1c23db8ed72b8a1e44f4b5af9d7739bf      1\n",
       "3    10221  299c9ab0f09d8dc281deaaad3260853e      5\n",
       "4    10221  34619be190aa19b20492e13da0cc1e45      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique list of users\n",
    "users = list(rating.user_id.unique())\n",
    "#unique list of songs\n",
    "songs = list(rating.track_id.unique())\n",
    "#count of interactions per user/item\n",
    "conf = list(rating['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign sequential user and item indicies for sparse matrix\n",
    "#assign category codes to user\n",
    "rows = rating.user_id.astype('category').cat.codes\n",
    "#assign category code to item\n",
    "cols = rating.track_id.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sparse matrix of users/items with interaction count as entry\n",
    "smat = sp.csr_matrix((conf,(rows,cols)),shape=(len(users),len(songs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21220x81343 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1053887 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check properties of sparse matrix\n",
    "smat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of the user/item matrix is 99.93894398121415\n"
     ]
    }
   ],
   "source": [
    "matrix_size = smat.shape[0]*smat.shape[1] # Number of possible interactions in the matrix\n",
    "num_listens = len(smat.nonzero()[0]) # Number of items interacted with\n",
    "sparsity = 100*(1 - (num_purchases/matrix_size))\n",
    "print(f'Sparsity of the user/item matrix is {sparsity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many machine learning applications, splitting the train and test sets is done by randomly sampling rows to set aside for training.  However, this method is inadequate for collaborative filtering because the interactions are needed to complete the matrix factorization.  Another method is to mask interactions in the training set, complete the matrix factorization, and compare the dot product of the latent vectors at the indices in which interactions were masked, to the unmasked interactions.  In this sense, the training set is altered, and the test set is the original user/item matrix.  This can be done by finding the nonzero interactions in the training matrix, set a percentage of them to 0, and record the indices. This is done in the following function.  The function outputs the train set, test set, and list of users who had an item masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    # copy original data for test set\n",
    "    test_set = ratings.copy()  \n",
    "    # set confidnece levels to 1: binary matrix\n",
    "    test_set[test_set != 0] = 1 \n",
    "    # Copy original data to mask users for train set\n",
    "    training_set = ratings.copy()  \n",
    "    # Find the interaction indices\n",
    "    nonzero_inds = training_set.nonzero() \n",
    "    # Zip non-zero entities into a list to sample from\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1]))\n",
    "    # Set the random seed \n",
    "    random.seed(0) \n",
    "    # Round the number of samples needed to the nearest integer\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) \n",
    "    # Sample user-item pairs without replacement\n",
    "    samples = random.sample(nonzero_pairs, num_samples) \n",
    "    # Get the user row indices\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    # Get the item column indices\n",
    "    item_inds = [index[1] for index in samples] \n",
    "    # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set[user_inds, item_inds] = 0 \n",
    "    # Get rid of zeros in sparse array storage after update to save space\n",
    "    training_set.eliminate_zeros() \n",
    "    # Output the unique list of user rows that were altered\n",
    "    return training_set, test_set, list(set(user_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function to create train/test split and masked user list \n",
    "train, test, masked_users = make_train(smat,pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21220x81343 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 843109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check properties of the train set\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21220x81343 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 1053887 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check properties of test set\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the propeties of each matrix shows that the dimensions are the same, with 20% less stored elements in the train set (items that were masked).  We an now fit the data to the alternating least sqaures model implemented in the implicit library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares with Implicit library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct the alternating least sqaures model using the implicit library.  The tuning parameter, alpha, is set to 40 and the model is called with the number of factos set to 20.  The output of the model will be the user and item vectors associated with the latent features of the matrix factorization.  These vectors are then used to make predictions by taking the dot product at the user indices where interactions were masked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This method is deprecated. Please use the AlternatingLeastSquares class instead\n",
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde3cf050bd5489da8354a4a12ae6e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#tuning parameter for confidence value\n",
    "alpha = 40\n",
    "user_vecs, item_vecs = implicit.alternating_least_squares((train*alpha).astype('double'), \n",
    "                                                          factors=20, \n",
    "                                                          regularization = 0.1, \n",
    "                                                          iterations = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21220, 20)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify user vector shape\n",
    "user_vecs.shape              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81343, 20)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #verify item vector shape\n",
    "    item_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation with AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the latent user and item feature vectors the next step is to make predictions by taking the dot product at the indices that were masked, and compare the results to binarixed test set.  As mentioned previously, access to the artist names and song titles are unavailable.  Because of this, there is no way to qualitatively access how the recommendation system is performing.  We will rely on the mean area under the curve metric for the interactions that were masked, and as comparison the popularity auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(predictions, test):\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "    return metrics.auc(fpr, tpr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_auc(training_set, altered_users, predictions, test_set):\n",
    "    \n",
    "     #empty lists to store scores\n",
    "    store_auc = [] \n",
    "    popularity_auc = [] \n",
    "    \n",
    "    # Get sum of item iteractions to find most popular\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1)\n",
    "    #Get latent item vectors\n",
    "    item_vecs = predictions[1]\n",
    "    for user in altered_users:\n",
    "        \n",
    "        #training set row, 1 dimensional vector\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) \n",
    "        # Find where the interaction had not yet occurred\n",
    "        zero_inds = np.where(training_row == 0) \n",
    "        # Get latent vectors for each user\n",
    "        user_vec = predictions[0][user,:]\n",
    "        #make predictions get only the indices with no interaction\n",
    "        pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "        # Select the binary interaction pairs from original data aligned with pairs from training\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "         # Get the item popularity for our chosen items\n",
    "        pop = pop_items[zero_inds]\n",
    "        #append auc scores to list\n",
    "        store_auc.append(auc_score(pred, actual))\n",
    "        #append popularity auc scores to list\n",
    "        popularity_auc.append(auc_score(pop, actual)) \n",
    "    \n",
    "    # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.916, 0.875)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_mean_auc(train, masked_users, \n",
    "              [sp.csr_matrix(user_vecs), sp.csr_matrix(item_vecs.T)],test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above results that the recommendation system outperformed the popularity model by about 4%.  Ideally, the parameters of the model would be searched to fine the optimal parameters. However, this is computationally expensive on the current system due to having to loop through the users with masked interactions.  To improve the model performance it would be better to add user/item features to add content metadata.  With the auc score for the ALS model being above 90%, this can be considered a good stopping point fo the ALS model, and we can pivot to constructing a model in lightfm that has the capability to create a hybrid model that includes matrix factorization and content modelling.  As mentioned before, we will not be creating a hybrid model, rather we can create a standard matrix factorization model in lightfm simply by not supplying any user or item features.  This will be used to compare the performance with the ALS model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightFM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In able to compare to the ALS model to another, we build a model in lightfm to compare the performance.  Using the lightfm model will also familiarize us to the library in the event the project is extended to creating a hybrid model in lightfm.  Lightfm provides utilities to make model fitting easy.  A model and parameters are defined, in addition to using the libraries data set class to create the internal indices for the model.  We then fit the model with the training set, and score with the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pseudo_bounce\\anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "# import lightfm library and auc_score function\n",
    "from lightfm import LightFM # model\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate light fm model with 20 components (same as als model)\n",
    "modelfm = LightFM(\n",
    "    no_components=20,\n",
    "    learning_rate=0.05,\n",
    "    loss='warp',\n",
    "    random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lightfm dataset class\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit dataset class with user/items while supplying no content features\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    users, \n",
    "    songs,\n",
    "    item_features=None, \n",
    "    user_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x213ad801348>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model on the training data\n",
    "modelfm.fit(\n",
    "    train,\n",
    "    item_features=None,\n",
    "    user_features=None, sample_weight=None,\n",
    "    epochs=5, num_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score the model on the test data\n",
    "score = auc_score( \n",
    "        modelfm, test, \n",
    "        item_features=None, \n",
    "        user_features=None, \n",
    "        num_threads=4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightfm auc score: 0.9372848272323608\n"
     ]
    }
   ],
   "source": [
    "print(f'Lightfm auc score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the standard lightfm model out-performs the ALS model by about 2% and the popularity model by 6%.  At this point we could try and improve the results by including user/item metadata to create a hybrid model, and grid-searching parameters to find the optimal values.  The hybrid model is beyond the scope of this work, but the project could be used as a starting point for further developement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
